{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c99f4ed-d6e8-4f0c-bdd4-bf6c1662a39f",
   "metadata": {},
   "source": [
    "# Lab 03: Text Classification on the DBpedia14 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74017-06ac-4e30-afe2-438f413d2a95",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "1. Build a Naive Bayes classification model from scratch\n",
    "2. Evaluate the performance of your model on the DBpedia14 dataset\n",
    "3. Train an off-the-shelf NB classifier and compare its performance to your implementation\n",
    "4. Train off-the-shelf implementations of the linear-SVM, RBF-kernel-SVM, and perceptron and compare their performance with the NB models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad5be2-5882-4cb6-95cb-18641199b02b",
   "metadata": {},
   "source": [
    "### Suggested Reading\n",
    "\n",
    "1. https://arxiv.org/pdf/1811.12808.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db7b42-9a27-45bd-b0e4-77106357c9d6",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be49292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jange 0.1.6 requires cytoolz<0.11.0,>=0.10.0, which is not installed.\n",
      "jange 0.1.6 requires more_itertools<9.0.0,>=8.4.0, which is not installed.\n",
      "jange 0.1.6 requires networkx<3.0,>=2.4, but you have networkx 2.3 which is incompatible.\n",
      "jange 0.1.6 requires pandas==1.0.5, but you have pandas 1.3.0 which is incompatible.\n",
      "jange 0.1.6 requires plotly<5.0.0,>=4.8.2, but you have plotly 5.1.0 which is incompatible.\n",
      "jange 0.1.6 requires spacy<3.0.0,>=2.2.0, but you have spacy 3.1.2 which is incompatible.\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\sangi\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from datasets) (1.21.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from datasets) (1.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from datasets) (21.0)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2021.9.0-py3-none-any.whl (123 kB)\n",
      "Collecting huggingface-hub<0.1.0,>=0.0.14\n",
      "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.10.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Collecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-5.0.0-cp38-cp38-win_amd64.whl (14.5 MB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Collecting tqdm>=4.62.1\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sangi\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sangi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Installing collected packages: tqdm, fsspec, dill, xxhash, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.2\n",
      "    Uninstalling tqdm-4.61.2:\n",
      "      Successfully uninstalled tqdm-4.61.2\n",
      "Successfully installed datasets-1.12.1 dill-0.3.4 fsspec-2021.9.0 huggingface-hub-0.0.17 multiprocess-0.70.12.2 pyarrow-5.0.0 tqdm-4.62.3 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83cd2ac-a840-4d36-b22d-3b4215cb99d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset d_bpedia14 (C:\\Users\\sangi\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8296f88ff88642af902f86649e47ed5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "train_ds, test_ds = datasets.load_dataset('dbpedia_14', split=['train[:80%]', 'test[80%:]'])\n",
    "df_train: pd.DataFrame = train_ds.to_pandas()\n",
    "df_test: pd.DataFrame = test_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1258edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E. D. Abbott Ltd</td>\n",
       "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Schwan-Stabilo</td>\n",
       "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Q-workshop</td>\n",
       "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Marvell Software Solutions Israel</td>\n",
       "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Bergan Mercy Medical Center</td>\n",
       "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                              title  \\\n",
       "0      0                   E. D. Abbott Ltd   \n",
       "1      0                     Schwan-Stabilo   \n",
       "2      0                         Q-workshop   \n",
       "3      0  Marvell Software Solutions Israel   \n",
       "4      0        Bergan Mercy Medical Center   \n",
       "\n",
       "                                             content  \n",
       "0   Abbott of Farnham E D Abbott Limited was a Br...  \n",
       "1   Schwan-STABILO is a German maker of pens for ...  \n",
       "2   Q-workshop is a Polish company located in Poz...  \n",
       "3   Marvell Software Solutions Israel known as RA...  \n",
       "4   Bergan Mercy Medical Center is a hospital loc...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc0c7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train.head(500)['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73e5813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Jedan od onih života...</td>\n",
       "      <td>Jedan od onih života... (trans. One of Those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Wanna Be a Star</td>\n",
       "      <td>Wanna Be a Star is the ninth album by the Can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>AOK (album)</td>\n",
       "      <td>AOK is a studio album by the Polish singer an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Coal (Leprous album)</td>\n",
       "      <td>Coal is the third studio album released by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>20th Century Masters – The Millennium Collecti...</td>\n",
       "      <td>20th Century Masters – The Millennium Collect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0     11                            Jedan od onih života...   \n",
       "1     11                                    Wanna Be a Star   \n",
       "2     11                                        AOK (album)   \n",
       "3     11                               Coal (Leprous album)   \n",
       "4     11  20th Century Masters – The Millennium Collecti...   \n",
       "\n",
       "                                             content  \n",
       "0   Jedan od onih života... (trans. One of Those ...  \n",
       "1   Wanna Be a Star is the ninth album by the Can...  \n",
       "2   AOK is a studio album by the Polish singer an...  \n",
       "3   Coal is the third studio album released by th...  \n",
       "4   20th Century Masters – The Millennium Collect...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a791197-515c-4dce-aac8-e8a4ba40be10",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part I: Build your own Naive Bayes classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2542f-9461-427d-93bb-1d39b1627afe",
   "metadata": {},
   "source": [
    "### (5 pts) Task I: Build a model from scratch\n",
    "Using your notes from lecture-02, implement a Naive Bayes model and train it on the DBpedia dataset. Also, feel free to use any text preprocessing you wish, such as the pipeline from Lab02. \n",
    "\n",
    "Below is a template class to help you think about the structure of this problem (feel free to design your own code if you like). It contains methods for each inference step in NB. It also has a classmethod that you could use to instantiate the class from a list of documents and a corresponding list of labels. Here we are suggesting you create a dictionary that maps each word to a unique $ith$ index in the $\\phi_{i,k}$ probabilty matrix, which you need to estimate. Because the labels are a set of 0-indexed integers, they naturally map to a unique position $\\mu_{k}$ (you should check this to make sure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a7fae75-aed4-46d4-8bca-b31fe3ce3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class NaiveBayesModel:\n",
    "    \n",
    "    \"\"\"Multinomial NB model class template\"\"\"\n",
    "    \n",
    "    phi: List[List[float]] # (N, K)\n",
    "    \n",
    "    mu: List[float]  # (K,)\n",
    "    \n",
    "    #vocab: dict     # vocabulary map from word to row index in phi\n",
    "    \n",
    "    #n_class: int    # number of classes\n",
    "        \n",
    "    words_counts: List[List[int]] # syntax?\n",
    "    \n",
    "    labels_list: List[int]\n",
    "        \n",
    "    n_words: int\n",
    "        \n",
    "    count_vectorizer: CountVectorizer\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_words: int, words_counts: List[List[int]], labels_list: List[int], count_vectorizer: CountVectorizer):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocabulary: {str: int} <- {word: index}\n",
    "        num_classes: Number of classes\n",
    "        \"\"\"\n",
    "        #vocab = vocabulary\n",
    "        #n_class = num_classes\n",
    "        self.words_counts = words_counts\n",
    "        self.labels_list = labels_list\n",
    "        self.n_words = n_words\n",
    "        self.count_vectorizer = count_vectorizer\n",
    "        self.mu = self.estimate_mu()\n",
    "        self.phi = self.estimate_phi()\n",
    "        return\n",
    "    \n",
    "    @classmethod\n",
    "    def from_preprocessed_data(cls, docs_list: List[str], labels_list: List[int]):\n",
    "        # Turn docs_list into count_vectorized df\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        count_vectorizer.fit(docs_list)\n",
    "        count_vector = count_vectorizer.transform(docs_list)\n",
    "        return cls(count_vector.shape[1], count_vector.toarray(), labels_list, count_vectorizer)\n",
    "    \n",
    "    def estimate_mu(self, alpha: float = 1.):\n",
    "        \"\"\"\n",
    "        Estimate P(Y), the prior over labels\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: smoothing parameter\n",
    "        \"\"\"\n",
    "        # p_y[i] = num occurrences of i / total rows\n",
    "        # p_y_given_x[i] = num occurrences where x (specific word) => y[i] / total rows (words?)\n",
    "        # p_x_given_y[n] = num occurrences where y and x[n] (specific word) / total rows (words?)\n",
    "        # self.mu\n",
    "        p = []\n",
    "        # assuming labels is length of the sample set, NOT unique labels\n",
    "        for i in range(len(self.labels_list)):\n",
    "            p.append(self.labels_list.count(self.labels_list[i]) / len(self.labels_list))\n",
    "        self.mu = p\n",
    "        return self.mu\n",
    "    \n",
    "    def estimate_phi(self, alpha: float = 1.):\n",
    "        \"\"\"\n",
    "        Estimate phi, the N x K matrix \n",
    "        describing the probability of\n",
    "        the nth word in the kth class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: smoothing parameter\n",
    "        \"\"\"\n",
    "        p = []\n",
    "        for n in range(self.n_words):\n",
    "            row = []\n",
    "            for i in range(len(set(self.labels_list))):\n",
    "                # replace 1s with word_counts[doc_ind][n] if we weight by count of the word in each document\n",
    "                sum_word_label = sum([1 if (self.labels_list[doc_ind] == list(set(self.labels_list))[i]) and (self.words_counts[doc_ind][n] != 0) \\\n",
    "                                      else 0 \\\n",
    "                                      for doc_ind in range(len(self.words_counts))])\n",
    "                count_word = sum([1 if self.words_counts[doc_ind][n] != 0 \\\n",
    "                                  else 0 \\\n",
    "                                  for doc_ind in range(len(self.words_counts))])\n",
    "                row.append(sum_word_label / count_word)\n",
    "            p.append(row)\n",
    "        self.phi = p\n",
    "        return self.phi\n",
    "    \n",
    "    def predict_label(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        Compute label given some input text\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: raw input text\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int: corresponding to the predicted label\n",
    "        \"\"\"\n",
    "        input_counts = self.count_vectorizer.transform(text).toarray()\n",
    "        probabilities = []\n",
    "        for i in range(len(self.mu)):\n",
    "            p = self.mu[i]\n",
    "            for n in input_counts[0]:\n",
    "                if not n == 0: # is this valid? Otherwise most things might zero out...\n",
    "                    p *= n\n",
    "            probabilities.append(p)\n",
    "        return probabilities.index(max(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4fc2ba-1443-44e4-b6cd-42fef40c677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available labels in the sample: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# turn df_train into docs_list and labels_list\n",
    "data_train = df_train.sample(500)  # full dataset is waaaaaay too big! (1.9TiB?!?!?!)\n",
    "docs_list = data_train['content'].tolist()\n",
    "labels_list = data_train['label'].tolist()\n",
    "print(\"Available labels in the sample: \" + str(set(labels_list)))\n",
    "# create NB object\n",
    "naiveBayesModel = NaiveBayesModel.from_preprocessed_data(docs_list, labels_list)\n",
    "# run from_preprocessed_data to initialize\n",
    "# test with one doc from df_test with predict_label method\n",
    "test_row = df_test.head(1)\n",
    "test_doc_list = test_row['content'].tolist()\n",
    "test_labels_list = test_row['label'].tolist()\n",
    "\n",
    "print(\"Testing 1 doc...\")\n",
    "print(naiveBayesModel.predict_label(test_row['content']))\n",
    "\n",
    "print(\"Testing all test docs!!!\")\n",
    "predictions = []\n",
    "count = 0\n",
    "for text in df_test['content'].tolist():\n",
    "    if count >= 10:\n",
    "        break\n",
    "    count += 1\n",
    "    predictions.append(naiveBayesModel.predict_label([text]))\n",
    "    \n",
    "test_labels = df_test['label'].tolist()\n",
    "    \n",
    "for i in range(len(predictions)):\n",
    "    print(\"Predicted: \" + str(predictions[i]) + \" -- Actual: \" + str(test_labels[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d193bce-b931-4cd6-b853-7bfb951bbcc5",
   "metadata": {},
   "source": [
    "# Part II: Model performance evaluation\n",
    "\n",
    "Evaluating the performance of a classification model may seem as simple as computing an accuracy, and in some cases that is sufficient, but in general accuracy is not a reliable metric by itself. Typically we need to evaluate our model using several different metrics. \n",
    "\n",
    "One common issue is class imbalance, which is when the label distribution in the data varies far from uniform. In this case a high accuracy can be misleading because low frequency labels don't contribute equally to the score. More generally, this is one of the biggest drawbacks of using MLE in NLP: models tend to be much less sensitive to low probability labels than to higher probabilty labels. Later in this class we will explore models that learn by predicting words given their context, can you think of reasons why this can be problematic? Hint: remember Zipf's law?\n",
    "\n",
    "Another reason to use multiple evaluation methods is that it can help you better understand your data. Evaluating performance on individual classes often reveals problems with the data that would otherwise go unnoticed. For example, if you observe an abundance of misclassified data specific to only a few classes, chances are you have inconsistent labels for those classes in the training set. This is very common in 3rd party mechanical turk data, where quality can vary wildly.\n",
    "\n",
    "In this lab we will use three metrics and one visualization tool:\n",
    "\n",
    "1. [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision)\n",
    "2. [F1 score](https://en.wikipedia.org/wiki/F-score)\n",
    "3. [AUC ROC score](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "4. [The confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "The [metrics module](https://scikit-learn.org/stable/modules/model_evaluation.html) within sklearn provides support for nearly any evaluation metric that you will need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801d31f-1131-476e-976d-02800bf01e56",
   "metadata": {},
   "source": [
    "# Part III: Compare your performance to an off-the-shelf NB classifier\n",
    "Open source implementations of your custom NB classifier from Part I already exist of course. One such implementation is [`sklearn.naive_bayes.MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) from the sklearn library. \n",
    "\n",
    "### (5 pts) Task II: NB model comparison\n",
    "Train this model on the same data and compare its performance with your model using the metrics from part II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e3f58-b1f7-471b-b3d0-35d1a55f6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d83a42-f957-467a-a101-8be81751f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dd830-2700-4fa7-81da-057c621e9c9d",
   "metadata": {},
   "source": [
    "# Part IV: Compare NB to other classification models\n",
    "\n",
    "Now that we've built and validated our NB classifier, we want to evaluate other models on this task.\n",
    "\n",
    "### (5 pts) Task III: Evaluate the perceptron, SVM (linear), and SVM (RBF kernel)\n",
    "Train and evaluate the following models on this dataset, and compare them with the NB models.\n",
    "\n",
    "1. [Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron)\n",
    "2. [Linear-SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n",
    "3. [RBF-Kernel-SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c9e19-7a6b-43d2-86e0-245654cda5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324363a9-ca97-4022-bdda-6dbf2b481279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4dea1-8ce3-4e2d-80e5-7d7ca3a1fc46",
   "metadata": {},
   "source": [
    "### (5 pts) Task IV: Select the best model\n",
    "\n",
    "1. Which model performed the best overall? \n",
    "2. What metric(s) influence this decision?\n",
    "3. Does the model that learns a non-linear decision boundary help?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
